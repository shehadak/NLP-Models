{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "FILENAME = \"../../Data/glove.6B/glove.6B.300d.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_vectors_from_file(filename):\n",
    "    d = {}\n",
    "    with open(filename, 'rt') as infile:\n",
    "        for line in infile:\n",
    "            parts = line.split()\n",
    "            word = parts[0]\n",
    "            rest = parts[1:]\n",
    "            d[word] = np.array(list(map(float, rest)))\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarity(v1, v2): return np.dot(v1, v2)/(np.linalg.norm(v1)*np.linalg.norm(v2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ecludian_distance(v1, v2): return np.linalg.norm(v1-v2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_analogy(e, w1, w2, w3):\n",
    "    # input: e: embedding vectors; w: word as string\n",
    "    # output: semantic np vector of a word x such that w1 : w2 :: w3 : x\n",
    "    return e[w2] - e[w1] + e[w3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_closest_words(e, v, n):\n",
    "    # input: e: embedding vectors; v: semantic vector; n: integer\n",
    "    # output: n words closest to vector v in the embeddings.\n",
    "    return sorted(e, key=lambda x: cosine_similarity(v, e[x]))[::-1][:n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [],
   "source": [
    "def similarity_two_sentences(e, s1, s2):\n",
    "    v1 = np.mean([e[w] for w in s1.split(' ')], axis=0)\n",
    "    v2 = np.mean([e[w] for w in s2.split(' ')], axis=0)\n",
    "    return cosine_similarity(v1, v2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "e = read_vectors_from_file(FILENAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = find_analogy(e, 'queen', 'king', 'boy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['boy',\n",
       " 'girl',\n",
       " 'man',\n",
       " 'son',\n",
       " 'father',\n",
       " 'kid',\n",
       " 'boys',\n",
       " 'brother',\n",
       " 'king',\n",
       " 'young',\n",
       " 'teenage',\n",
       " 'uncle',\n",
       " 'woman',\n",
       " 'child',\n",
       " 'teenager',\n",
       " 'parents',\n",
       " 'girls',\n",
       " 'him',\n",
       " 'kids',\n",
       " 'mother']"
      ]
     },
     "execution_count": 415,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_closest_words(e, y, 20)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
